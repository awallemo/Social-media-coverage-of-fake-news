In our first meeting we got information on what we should be look more into:
- Create a GitHub repository 
- Create a timeline 
- Cover three social media
	- Twitter, Reddit and Facebook (if possible). We could also use another social media(look 			 		    
           more into this
- Vinay suggested us that we divide the the project into three parts:

	- Frontend 
		- Take the fact we want to check and pass it to the backend
		- How the information is shown(a cool design)
	- Backend 
		- Searching part. The the query and see how much is reached. How much it has covered on the social media. 	  	
		How much it has been retweeted.
		- Find the right API.
		- Use Score functions. This is also used in Search Engines 
		- Tagging named entities (a service called tagMe https://services.d4science.org/web/tagme/)
- the code should be finished by April

Meeting Thursday 14.January: 
- In our second meeting with vinay we looked more specifically at the hoaxy website
- We want to figure out a way to filter out any unrelevant and unneccessary posts when we are searching in the app.

- Typical use cases:
	- Compare two or more posts(statements) related to the same theme. Fex "Capitol Hill attack done by Antifa thugs" vs "Capitol Hill attack done by Trump-	supporters"
	
	- Compare two or more posts(statements) that are not related to the same theme.
- Use the google fact checker API to fact check different statements
- Make the searches more specific, clarify what the queries are about. Fex if you search for something apple related the app should be able to know if you are searching for an actual apple or the company named Apple.

- Check out "tagme" link is in the notes


26. Jan 
- Trouble running the backend. Not connecting to the database.
- screen -r 
- some update on the frontend
	- looking at some charts with d3. 
	- adding buttons to expand the details. 
- until next week we will try to visualise some data on some chart & have the backend running
- Get access to the ssh 
- SSHFS working with visual Studio 


Meeting February 2nd:

In this meeting we showed how far we had come with our page, we started testing with a graph and some queries.
- We need to get several models to present the data aswell as add a timeline of how much the tweet is spreadigng over time.
- Vinay showed us how to use SSHFS to be able to edit the files in the ubuntu virtual env. locally on our computer
	- Download sshfs
	- make a directory mkdir users/awallemo/hoaxy
	- Write the command 'sshfs -o allow_other,defer_permissions,IdentityFile=~/.ssh/id_rsa ubuntu@18.222.210.219:/home/ubuntu/users/awallemo/hoaxy
- We asked Vinay to explain more about how the hoaxy backend on ubuntu works, i.e how to edit it and how the server communicates with the client
	- We use sshfs to edit the files on our computer locally, which means we can run and edit the code in vscode.
	- The client communicates with the server using RestAPI(?)
	- Use the different APIs for the different functions on the site: searching tweets, searching articles, trending news, popular news 
 
 Meeting February 9nd:
 
- We were having difficulties with running the backend and also with the automatic deployment of the backend so Vinay said he would take a look at it.
- Read up on screen commands, this is used in the steps with "Running the backend for the first time".
- We asked how to go forward with the frontend of the application when we don't have any good backend available at the moment
	- we should try to implement the Hoaxy api in out frontend and see how we can get more and diverse data out. 
